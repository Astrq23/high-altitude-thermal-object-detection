{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install -q ultralytics imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "import os\n",
    "import requests\n",
    "import zipfile\n",
    "import cv2\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "ROOT_DIR = '/kaggle/input/hituav-a-highaltitude-infrared-thermal-dataset/hit-uav'\n",
    "train_imgs_dir = 'images/train'\n",
    "train_labels_dir = 'labels/train'\n",
    "val_imgs_dir = 'images/val'\n",
    "val_labels_dir = 'labels/val'\n",
    "test_imgs_dir = 'images/test'\n",
    "test_labels_dir = 'labels/test'\n",
    "classes = ['Person', 'Car', 'Bicycle', 'OtherVechicle', 'DontCare']\n",
    "colors = np.random.uniform(0, 255, size=(len(classes), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Function to convert bounding boxes in YOLO format to xmin, ymin, xmax, ymax.\n",
    "def yolo2bbox(bboxes):\n",
    "    xmin, ymin = bboxes[0]-bboxes[2]/2, bboxes[1]-bboxes[3]/2\n",
    "    xmax, ymax = bboxes[0]+bboxes[2]/2, bboxes[1]+bboxes[3]/2\n",
    "    return xmin, ymin, xmax, ymax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def plot_box(image, bboxes, labels, classes=classes, colors=colors, pos='above'):\n",
    "    # Need the image height and width to denormalize\n",
    "    # the bounding box coordinates\n",
    "    height, width, _ = image.shape\n",
    "    lw = max(round(sum(image.shape) / 2 * 0.003), 2)  # Line width.\n",
    "    tf = max(lw - 1, 1) # Font thickness.\n",
    "    for box_num, box in enumerate(bboxes):\n",
    "        x1, y1, x2, y2 = yolo2bbox(box)\n",
    "        # denormalize the coordinates\n",
    "        xmin = int(x1*width)\n",
    "        ymin = int(y1*height)\n",
    "        xmax = int(x2*width)\n",
    "        ymax = int(y2*height)\n",
    "\n",
    "        p1, p2 = (int(xmin), int(ymin)), (int(xmax), int(ymax))\n",
    "        \n",
    "        class_name = classes[int(labels[box_num])]\n",
    "\n",
    "        color=colors[classes.index(class_name)]\n",
    "        \n",
    "        cv2.rectangle(\n",
    "            image, \n",
    "            p1, p2,\n",
    "            color=color, \n",
    "            thickness=lw,\n",
    "            lineType=cv2.LINE_AA\n",
    "        ) \n",
    "\n",
    "        # For filled rectangle.\n",
    "        w, h = cv2.getTextSize(\n",
    "            class_name, \n",
    "            0, \n",
    "            fontScale=lw / 3, \n",
    "            thickness=tf\n",
    "        )[0]\n",
    "\n",
    "        outside = p1[1] - h >= 3\n",
    "        \n",
    "        if pos == 'above':\n",
    "            p2 = p1[0] + w, p1[1] - h - 3 if outside else p1[1] + h + 3\n",
    "            cv2.rectangle(\n",
    "                image, \n",
    "                p1, p2, \n",
    "                color=color, \n",
    "                thickness=-1, \n",
    "                lineType=cv2.LINE_AA\n",
    "            )  \n",
    "            cv2.putText(\n",
    "                image, \n",
    "                class_name, \n",
    "                (p1[0], p1[1] - 5 if outside else p1[1] + h + 2),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                fontScale=lw/3.5, \n",
    "                color=(255, 255, 255), \n",
    "                thickness=tf, \n",
    "                lineType=cv2.LINE_AA\n",
    "            )\n",
    "        else:\n",
    "            new_p2 = p1[0] + w, p2[1] + h + 3 if outside else p2[1] - h - 3\n",
    "            cv2.rectangle(\n",
    "                image, \n",
    "                (p1[0], p2[1]), new_p2, \n",
    "                color=color, \n",
    "                thickness=-1, \n",
    "                lineType=cv2.LINE_AA\n",
    "            )  \n",
    "            cv2.putText(\n",
    "                image, \n",
    "                class_name, \n",
    "                (p1[0], p2[1] + h + 2 if outside else p2[1]),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                fontScale=lw/3, \n",
    "                color=(255, 255, 255), \n",
    "                thickness=tf, \n",
    "                lineType=cv2.LINE_AA\n",
    "            )\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Function to plot images with the bounding boxes.\n",
    "def plot(image_path, label_path, num_samples, classes=classes, colors=colors, pos='above'):\n",
    "    all_training_images = glob.glob(image_path+'/*')\n",
    "    all_training_labels = glob.glob(label_path+'/*')\n",
    "    all_training_images.sort()\n",
    "    all_training_labels.sort()\n",
    "    \n",
    "    temp = list(zip(all_training_images, all_training_labels))\n",
    "    random.shuffle(temp)\n",
    "    all_training_images, all_training_labels = zip(*temp)\n",
    "    all_training_images, all_training_labels = list(all_training_images), list(all_training_labels)\n",
    "    \n",
    "    num_images = len(all_training_images)\n",
    "    \n",
    "    if num_samples == -1:\n",
    "        num_samples = num_images\n",
    "    \n",
    "    num_cols = 2\n",
    "    num_rows = int(math.ceil(num_samples / num_cols))\n",
    "        \n",
    "    plt.figure(figsize=(10 * num_cols, 6 * num_rows))\n",
    "    for i in range(num_samples):\n",
    "        image_name = all_training_images[i].split(os.path.sep)[-1]\n",
    "        image = cv2.imread(all_training_images[i])\n",
    "        with open(all_training_labels[i], 'r') as f:\n",
    "            bboxes = []\n",
    "            labels = []\n",
    "            label_lines = f.readlines()\n",
    "            for label_line in label_lines:\n",
    "                label, x_c, y_c, w, h = label_line.split(' ')\n",
    "                x_c = float(x_c)\n",
    "                y_c = float(y_c)\n",
    "                w = float(w)\n",
    "                h = float(h)\n",
    "                bboxes.append([x_c, y_c, w, h])\n",
    "                labels.append(label)\n",
    "        result_image = plot_box(image, bboxes, labels, classes, colors, pos)\n",
    "        plt.subplot(num_rows, num_cols, i+1) # Visualize 2x2 grid of images.\n",
    "        plt.imshow(image[:, :, ::-1])\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Visualize a few training images.\n",
    "plot(\n",
    "    image_path=os.path.join(ROOT_DIR, train_imgs_dir), \n",
    "    label_path=os.path.join(ROOT_DIR, train_labels_dir),\n",
    "    num_samples=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "# 1. Tạo file dataset.yaml\n",
    "data_dict = {\n",
    "    \"train\": \"/kaggle/input/hituav-a-highaltitude-infrared-thermal-dataset/hit-uav/images/train\",\n",
    "    \"val\": \"/kaggle/input/hituav-a-highaltitude-infrared-thermal-dataset/hit-uav/images/val\",\n",
    "    \"test\": \"/kaggle/input/hituav-a-highaltitude-infrared-thermal-dataset/hit-uav/images/test\",\n",
    "    \"nc\": 5,\n",
    "    \"names\": ['Person', 'Car', 'Bicycle', 'OtherVehicle', 'DontCare']\n",
    "}\n",
    "\n",
    "with open(\"dataset.yaml\", \"w\") as f:\n",
    "    yaml.dump(data_dict, f, sort_keys=False)\n",
    "\n",
    "\n",
    "# 2. Tạo file model config (Sửa phần Backbone)\n",
    "model_dict = {\n",
    "    \"nc\": 5, \n",
    "    \n",
    "    \"backbone\": [\n",
    "        # [from, repeats, module, args]\n",
    "        \n",
    "        # --- THAY ĐỔI Ở ĐÂY: Đổi \"convnext_tiny\" thành \"convnext_small\" ---\n",
    "        # ConvNeXt-Small output channels cuối cùng vẫn là 768 giống Tiny\n",
    "        [-1, 1, \"TorchVision\", [768, \"convnext_small\", \"DEFAULT\", True, 2, True]], # ### <--- ĐÃ SỬA\n",
    "        \n",
    "        [-1, 1, \"nn.Identity\", []], \n",
    "        [-1, 1, \"nn.Identity\", []], \n",
    "\n",
    "        # ------ P3 Branch (Target: 256 channels)\n",
    "        # ConvNeXt-Small Stage 2 cũng có 192 channels -> Giữ nguyên\n",
    "        [0, 1, \"Index\", [192, 4]], \n",
    "        [-1, 1, \"Conv\", [256, 1, 1]], \n",
    "        [-1, 1, \"nn.Identity\", []], # index 5 (P3)\n",
    "\n",
    "        # --------- P4 Branch (Target: 512 channels)\n",
    "        # ConvNeXt-Small Stage 3 cũng có 384 channels -> Giữ nguyên\n",
    "        [0, 1, \"Index\", [384, 6]], \n",
    "        [-1, 1, \"Conv\", [512, 1, 1]], \n",
    "        [-1, 1, \"nn.Identity\", []], # index 8 (P4)\n",
    "\n",
    "        # ------------------------- P5 Branch (Target: 1024 channels)\n",
    "        # ConvNeXt-Small Stage 4 cũng có 768 channels -> Giữ nguyên\n",
    "        [0, 1, \"Index\", [768, 8]], \n",
    "        [-1, 1, \"Conv\", [1024, 1, 1]], \n",
    "        [-1, 1, \"SPPF\", [1024, 5]] # index 11 (P5)\n",
    "    ],\n",
    "    \"head\": [\n",
    "        # Phần Head giữ nguyên hoàn toàn\n",
    "        [-1, 1, \"nn.Upsample\", [None, 2, \"nearest\"]],\n",
    "        [[-1, 8], 1, \"Concat\", [1]], \n",
    "        [-1, 3, \"C2f\", [512, True]], # index 14\n",
    "\n",
    "        [-1, 1, \"nn.Upsample\", [None, 2, \"nearest\"]],\n",
    "        [[-1, 5], 1, \"Concat\", [1]], \n",
    "        [-1, 3, \"C2f\", [256, True]], # index 17 (Output P3)\n",
    "\n",
    "        [-1, 1, \"Conv\", [256, 3, 2]],\n",
    "        [[-1, 14], 1, \"Concat\", [1]], \n",
    "        [-1, 3, \"C2f\", [512, True]], # index 20 (Output P4)\n",
    "\n",
    "        [-1, 1, \"Conv\", [512, 3, 2]],\n",
    "        [[-1, 11], 1, \"Concat\", [1]], \n",
    "        [-1, 3, \"C2f\", [1024, True]], # index 23 (Output P5)\n",
    "\n",
    "        [[17, 20, 23], 1, \"Detect\", [\"nc\"]] \n",
    "    ]\n",
    "}\n",
    "\n",
    "with open(\"yolov8-custom.yaml\", \"w\") as f:\n",
    "    yaml.dump(model_dict, f, sort_keys=False)\n",
    "\n",
    "print(\"Đã tạo file yolov8-custom.yaml với backbone ConvNeXt-Small thành công!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "yolo_efficientnet_model = YOLO('/kaggle/working/yolov8-custom.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "yolo_efficientnet_train = yolo_efficientnet_model.train(data=\"/kaggle/working/dataset.yaml\", epochs=50, batch = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "best_efficientnet_model = YOLO('/kaggle/working/runs/detect/train/weights/best.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from imutils import paths\n",
    "\n",
    "log_dir = \"/kaggle/working/runs/detect/train\"\n",
    "for image_path in sorted(paths.list_images(log_dir)):\n",
    "    image = Image.open(image_path)\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.imshow(image)\n",
    "    plt.title(os.path.basename(image_path))\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!zip -r /kaggle/working/runs.zip runs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!ls -lh /kaggle/working/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference on Test Images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "results = best_efficientnet_model(os.path.join(ROOT_DIR, test_imgs_dir), conf=0.5, agnostic_nms=True, iou=0.5, save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_random_result(results):\n",
    "    random_result = random.choice(results)   \n",
    "    img = random_result.plot()               \n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.imshow(img)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "show_random_result(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "show_random_result(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "show_random_result(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "indices = list(range(len(results)))\n",
    "random_indices = random.sample(indices, 10)\n",
    "num_cols = 2\n",
    "num_rows = 5\n",
    "\n",
    "plt.figure(figsize=(12 * num_cols, 6 * num_rows))\n",
    "    \n",
    "for i, idx in enumerate(random_indices):\n",
    "    image = results[i].plot()\n",
    "    plt.subplot(num_rows, num_cols, i+1)\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare predictions with ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "ground_colors = [(255, 0, 0) for _ in range(len(classes))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!ls runs/detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "success = best_efficientnet_model.export(format=\"onnx\")  # export the model to ONNX format\n",
    "success"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 2859502,
     "sourceId": 4931060,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
